{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = r\"D:\\data_science\\train\"\n",
    "val_dir = r\"D:\\data_science\\test\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(BatchNormalization())\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(BatchNormalization())\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(BatchNormalization())\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(BatchNormalization())\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(BatchNormalization())\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(BatchNormalization())\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(256, activation='relu'))\n",
    "emotion_model.add(BatchNormalization())\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manav\\AppData\\Local\\Temp\\ipykernel_14288\\2857620097.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  emotion_model_info = emotion_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 308s 685ms/step - loss: 2.2838 - accuracy: 0.2488 - val_loss: 1.6519 - val_accuracy: 0.3686\n",
      "Epoch 2/100\n",
      "448/448 [==============================] - 156s 347ms/step - loss: 2.0552 - accuracy: 0.3022 - val_loss: 1.5980 - val_accuracy: 0.3864\n",
      "Epoch 3/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 1.9121 - accuracy: 0.3360 - val_loss: 1.5222 - val_accuracy: 0.4203\n",
      "Epoch 4/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.7871 - accuracy: 0.3639 - val_loss: 1.4711 - val_accuracy: 0.4411\n",
      "Epoch 5/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 1.6893 - accuracy: 0.3909 - val_loss: 1.4169 - val_accuracy: 0.4644\n",
      "Epoch 6/100\n",
      "448/448 [==============================] - 165s 367ms/step - loss: 1.6228 - accuracy: 0.4045 - val_loss: 1.3904 - val_accuracy: 0.4706\n",
      "Epoch 7/100\n",
      "448/448 [==============================] - 164s 367ms/step - loss: 1.5564 - accuracy: 0.4198 - val_loss: 1.3662 - val_accuracy: 0.4813\n",
      "Epoch 8/100\n",
      "448/448 [==============================] - 168s 374ms/step - loss: 1.5118 - accuracy: 0.4342 - val_loss: 1.3361 - val_accuracy: 0.4922\n",
      "Epoch 9/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.4651 - accuracy: 0.4509 - val_loss: 1.3173 - val_accuracy: 0.5008\n",
      "Epoch 10/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.4225 - accuracy: 0.4609 - val_loss: 1.2778 - val_accuracy: 0.5146\n",
      "Epoch 11/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 1.3873 - accuracy: 0.4774 - val_loss: 1.2668 - val_accuracy: 0.5191\n",
      "Epoch 12/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 1.3602 - accuracy: 0.4874 - val_loss: 1.2506 - val_accuracy: 0.5287\n",
      "Epoch 13/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 1.3304 - accuracy: 0.4964 - val_loss: 1.2526 - val_accuracy: 0.5297\n",
      "Epoch 14/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.2987 - accuracy: 0.5067 - val_loss: 1.2217 - val_accuracy: 0.5414\n",
      "Epoch 15/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.2792 - accuracy: 0.5147 - val_loss: 1.2183 - val_accuracy: 0.5423\n",
      "Epoch 16/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.2556 - accuracy: 0.5242 - val_loss: 1.1820 - val_accuracy: 0.5501\n",
      "Epoch 17/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.2347 - accuracy: 0.5334 - val_loss: 1.2023 - val_accuracy: 0.5403\n",
      "Epoch 18/100\n",
      "448/448 [==============================] - 166s 372ms/step - loss: 1.2158 - accuracy: 0.5366 - val_loss: 1.1833 - val_accuracy: 0.5479\n",
      "Epoch 19/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 1.1972 - accuracy: 0.5465 - val_loss: 1.1556 - val_accuracy: 0.5604\n",
      "Epoch 20/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.1822 - accuracy: 0.5538 - val_loss: 1.1463 - val_accuracy: 0.5653\n",
      "Epoch 21/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 1.1616 - accuracy: 0.5606 - val_loss: 1.1393 - val_accuracy: 0.5699\n",
      "Epoch 22/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.1450 - accuracy: 0.5646 - val_loss: 1.1278 - val_accuracy: 0.5734\n",
      "Epoch 23/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.1297 - accuracy: 0.5710 - val_loss: 1.1100 - val_accuracy: 0.5797\n",
      "Epoch 24/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.1161 - accuracy: 0.5810 - val_loss: 1.1100 - val_accuracy: 0.5770\n",
      "Epoch 25/100\n",
      "448/448 [==============================] - 167s 374ms/step - loss: 1.1037 - accuracy: 0.5826 - val_loss: 1.1025 - val_accuracy: 0.5826\n",
      "Epoch 26/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.0895 - accuracy: 0.5916 - val_loss: 1.1028 - val_accuracy: 0.5866\n",
      "Epoch 27/100\n",
      "448/448 [==============================] - 167s 372ms/step - loss: 1.0798 - accuracy: 0.5944 - val_loss: 1.0937 - val_accuracy: 0.5866\n",
      "Epoch 28/100\n",
      "448/448 [==============================] - 167s 372ms/step - loss: 1.0556 - accuracy: 0.6049 - val_loss: 1.0856 - val_accuracy: 0.5933\n",
      "Epoch 29/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 1.0424 - accuracy: 0.6083 - val_loss: 1.1031 - val_accuracy: 0.5890\n",
      "Epoch 30/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 1.0352 - accuracy: 0.6123 - val_loss: 1.0796 - val_accuracy: 0.5975\n",
      "Epoch 31/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.0181 - accuracy: 0.6173 - val_loss: 1.0846 - val_accuracy: 0.5944\n",
      "Epoch 32/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 1.0091 - accuracy: 0.6214 - val_loss: 1.0710 - val_accuracy: 0.6013\n",
      "Epoch 33/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 1.0007 - accuracy: 0.6273 - val_loss: 1.0646 - val_accuracy: 0.6020\n",
      "Epoch 34/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.9878 - accuracy: 0.6293 - val_loss: 1.0705 - val_accuracy: 0.6025\n",
      "Epoch 35/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.9767 - accuracy: 0.6374 - val_loss: 1.0651 - val_accuracy: 0.6037\n",
      "Epoch 36/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.9682 - accuracy: 0.6379 - val_loss: 1.0713 - val_accuracy: 0.6018\n",
      "Epoch 37/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.9509 - accuracy: 0.6444 - val_loss: 1.0552 - val_accuracy: 0.6151\n",
      "Epoch 38/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.9448 - accuracy: 0.6476 - val_loss: 1.0543 - val_accuracy: 0.6130\n",
      "Epoch 39/100\n",
      "448/448 [==============================] - 167s 373ms/step - loss: 0.9300 - accuracy: 0.6499 - val_loss: 1.0577 - val_accuracy: 0.6159\n",
      "Epoch 40/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.9207 - accuracy: 0.6603 - val_loss: 1.0578 - val_accuracy: 0.6136\n",
      "Epoch 41/100\n",
      "448/448 [==============================] - 167s 373ms/step - loss: 0.9061 - accuracy: 0.6655 - val_loss: 1.0522 - val_accuracy: 0.6136\n",
      "Epoch 42/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.8979 - accuracy: 0.6605 - val_loss: 1.0543 - val_accuracy: 0.6119\n",
      "Epoch 43/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.8861 - accuracy: 0.6708 - val_loss: 1.0657 - val_accuracy: 0.6137\n",
      "Epoch 44/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 0.8762 - accuracy: 0.6751 - val_loss: 1.0502 - val_accuracy: 0.6170\n",
      "Epoch 45/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.8674 - accuracy: 0.6789 - val_loss: 1.0557 - val_accuracy: 0.6215\n",
      "Epoch 46/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.8580 - accuracy: 0.6804 - val_loss: 1.0763 - val_accuracy: 0.6102\n",
      "Epoch 47/100\n",
      "448/448 [==============================] - 169s 378ms/step - loss: 0.8428 - accuracy: 0.6864 - val_loss: 1.0612 - val_accuracy: 0.6191\n",
      "Epoch 48/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.8372 - accuracy: 0.6904 - val_loss: 1.0720 - val_accuracy: 0.6161\n",
      "Epoch 49/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.8259 - accuracy: 0.6935 - val_loss: 1.0619 - val_accuracy: 0.6172\n",
      "Epoch 50/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.8185 - accuracy: 0.6972 - val_loss: 1.0550 - val_accuracy: 0.6201\n",
      "Epoch 51/100\n",
      "448/448 [==============================] - 167s 373ms/step - loss: 0.8068 - accuracy: 0.7012 - val_loss: 1.0558 - val_accuracy: 0.6211\n",
      "Epoch 52/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.7989 - accuracy: 0.7062 - val_loss: 1.0613 - val_accuracy: 0.6201\n",
      "Epoch 53/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.7880 - accuracy: 0.7077 - val_loss: 1.0660 - val_accuracy: 0.6214\n",
      "Epoch 54/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.7781 - accuracy: 0.7119 - val_loss: 1.0765 - val_accuracy: 0.6183\n",
      "Epoch 55/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 0.7682 - accuracy: 0.7141 - val_loss: 1.0707 - val_accuracy: 0.6244\n",
      "Epoch 56/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.7574 - accuracy: 0.7221 - val_loss: 1.0783 - val_accuracy: 0.6215\n",
      "Epoch 57/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.7483 - accuracy: 0.7232 - val_loss: 1.0894 - val_accuracy: 0.6217\n",
      "Epoch 58/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.7380 - accuracy: 0.7277 - val_loss: 1.0888 - val_accuracy: 0.6239\n",
      "Epoch 59/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.7333 - accuracy: 0.7275 - val_loss: 1.0941 - val_accuracy: 0.6246\n",
      "Epoch 60/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.7194 - accuracy: 0.7334 - val_loss: 1.0852 - val_accuracy: 0.6240\n",
      "Epoch 61/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.7132 - accuracy: 0.7380 - val_loss: 1.1027 - val_accuracy: 0.6233\n",
      "Epoch 62/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.7068 - accuracy: 0.7354 - val_loss: 1.1004 - val_accuracy: 0.6310\n",
      "Epoch 63/100\n",
      "448/448 [==============================] - 167s 373ms/step - loss: 0.6994 - accuracy: 0.7406 - val_loss: 1.0993 - val_accuracy: 0.6277\n",
      "Epoch 64/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.6834 - accuracy: 0.7435 - val_loss: 1.1147 - val_accuracy: 0.6253\n",
      "Epoch 65/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.6827 - accuracy: 0.7471 - val_loss: 1.1186 - val_accuracy: 0.6201\n",
      "Epoch 66/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 0.6674 - accuracy: 0.7519 - val_loss: 1.1109 - val_accuracy: 0.6281\n",
      "Epoch 67/100\n",
      "448/448 [==============================] - 167s 372ms/step - loss: 0.6613 - accuracy: 0.7537 - val_loss: 1.1154 - val_accuracy: 0.6263\n",
      "Epoch 68/100\n",
      "448/448 [==============================] - 168s 375ms/step - loss: 0.6599 - accuracy: 0.7533 - val_loss: 1.1264 - val_accuracy: 0.6253\n",
      "Epoch 69/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.6495 - accuracy: 0.7607 - val_loss: 1.1259 - val_accuracy: 0.6239\n",
      "Epoch 70/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.6402 - accuracy: 0.7622 - val_loss: 1.1239 - val_accuracy: 0.6267\n",
      "Epoch 71/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.6417 - accuracy: 0.7652 - val_loss: 1.1247 - val_accuracy: 0.6283\n",
      "Epoch 72/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.6279 - accuracy: 0.7698 - val_loss: 1.1262 - val_accuracy: 0.6261\n",
      "Epoch 73/100\n",
      "448/448 [==============================] - 167s 373ms/step - loss: 0.6195 - accuracy: 0.7693 - val_loss: 1.1355 - val_accuracy: 0.6264\n",
      "Epoch 74/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.6152 - accuracy: 0.7703 - val_loss: 1.1632 - val_accuracy: 0.6211\n",
      "Epoch 75/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.6062 - accuracy: 0.7787 - val_loss: 1.1458 - val_accuracy: 0.6253\n",
      "Epoch 76/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 0.6046 - accuracy: 0.7767 - val_loss: 1.1688 - val_accuracy: 0.6222\n",
      "Epoch 77/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5914 - accuracy: 0.7802 - val_loss: 1.1692 - val_accuracy: 0.6189\n",
      "Epoch 78/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5830 - accuracy: 0.7854 - val_loss: 1.1749 - val_accuracy: 0.6179\n",
      "Epoch 79/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.5771 - accuracy: 0.7878 - val_loss: 1.1717 - val_accuracy: 0.6253\n",
      "Epoch 80/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5759 - accuracy: 0.7904 - val_loss: 1.1832 - val_accuracy: 0.6204\n",
      "Epoch 81/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5731 - accuracy: 0.7890 - val_loss: 1.1760 - val_accuracy: 0.6267\n",
      "Epoch 82/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.5560 - accuracy: 0.7954 - val_loss: 1.2139 - val_accuracy: 0.6253\n",
      "Epoch 83/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5534 - accuracy: 0.7993 - val_loss: 1.1934 - val_accuracy: 0.6286\n",
      "Epoch 84/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.5458 - accuracy: 0.7992 - val_loss: 1.1944 - val_accuracy: 0.6296\n",
      "Epoch 85/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5434 - accuracy: 0.7998 - val_loss: 1.2051 - val_accuracy: 0.6240\n",
      "Epoch 86/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5412 - accuracy: 0.8006 - val_loss: 1.1943 - val_accuracy: 0.6215\n",
      "Epoch 87/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.5320 - accuracy: 0.8051 - val_loss: 1.2137 - val_accuracy: 0.6246\n",
      "Epoch 88/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5300 - accuracy: 0.8061 - val_loss: 1.2023 - val_accuracy: 0.6244\n",
      "Epoch 89/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.5267 - accuracy: 0.8077 - val_loss: 1.2031 - val_accuracy: 0.6264\n",
      "Epoch 90/100\n",
      "448/448 [==============================] - 166s 372ms/step - loss: 0.5152 - accuracy: 0.8084 - val_loss: 1.2193 - val_accuracy: 0.6257\n",
      "Epoch 91/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.5138 - accuracy: 0.8105 - val_loss: 1.2129 - val_accuracy: 0.6288\n",
      "Epoch 92/100\n",
      "448/448 [==============================] - 166s 369ms/step - loss: 0.4983 - accuracy: 0.8160 - val_loss: 1.2388 - val_accuracy: 0.6313\n",
      "Epoch 93/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.4967 - accuracy: 0.8170 - val_loss: 1.2278 - val_accuracy: 0.6268\n",
      "Epoch 94/100\n",
      "448/448 [==============================] - 167s 372ms/step - loss: 0.5013 - accuracy: 0.8186 - val_loss: 1.2364 - val_accuracy: 0.6297\n",
      "Epoch 95/100\n",
      "448/448 [==============================] - 166s 370ms/step - loss: 0.4846 - accuracy: 0.8223 - val_loss: 1.2481 - val_accuracy: 0.6278\n",
      "Epoch 96/100\n",
      "448/448 [==============================] - 165s 369ms/step - loss: 0.4855 - accuracy: 0.8216 - val_loss: 1.2407 - val_accuracy: 0.6270\n",
      "Epoch 97/100\n",
      "448/448 [==============================] - 168s 376ms/step - loss: 0.4834 - accuracy: 0.8223 - val_loss: 1.2414 - val_accuracy: 0.6235\n",
      "Epoch 98/100\n",
      "448/448 [==============================] - 171s 382ms/step - loss: 0.4791 - accuracy: 0.8260 - val_loss: 1.2471 - val_accuracy: 0.6257\n",
      "Epoch 99/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.4686 - accuracy: 0.8294 - val_loss: 1.2561 - val_accuracy: 0.6279\n",
      "Epoch 100/100\n",
      "448/448 [==============================] - 166s 371ms/step - loss: 0.4642 - accuracy: 0.8298 - val_loss: 1.2671 - val_accuracy: 0.6251\n"
     ]
    }
   ],
   "source": [
    "emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=emotion_model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
